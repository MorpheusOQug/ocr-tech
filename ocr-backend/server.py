from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
import torch
import torchvision.transforms as T
from PIL import Image
from torchvision.transforms.functional import InterpolationMode
import uvicorn
import io
import os
import sys

# Th√™m th∆∞ m·ª•c g·ªëc v√†o sys.path ƒë·ªÉ c√≥ th·ªÉ import module t·ª´ th∆∞ m·ª•c cha
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from load_model import load_ocr_model #Load model t·ª´ file load_model.py

# Kh·ªüi t·∫°o FastAPI
app = FastAPI()

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Cho ph√©p t·∫•t c·∫£ c√°c ngu·ªìn
    allow_credentials=True,
    allow_methods=["*"],  # Cho ph√©p t·∫•t c·∫£ c√°c ph∆∞∆°ng th·ª©c
    allow_headers=["*"],  # Cho ph√©p t·∫•t c·∫£ c√°c header
)

# H·∫±ng s·ªë ti·ªÅn x·ª≠ l√Ω ·∫£nh
IMAGENET_MEAN = (0.485, 0.456, 0.406)
IMAGENET_STD = (0.229, 0.224, 0.225)

# T·∫£i m√¥ h√¨nh OCR **m·ªôt l·∫ßn duy nh·∫•t** khi server kh·ªüi ƒë·ªông
print("üîÑ ƒêang t·∫£i m√¥ h√¨nh OCR...")
model, tokenizer = load_ocr_model()
print("‚úÖ M√¥ h√¨nh ƒë√£ t·∫£i xong!")

# H√†m ti·ªÅn x·ª≠ l√Ω ·∫£nh
def build_transform(input_size):
    transform = T.Compose([
        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),
        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),
        T.ToTensor(),
        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
    ])
    return transform

# H√†m x·ª≠ l√Ω ·∫£nh
def process_image(image_data, input_size=448):
    image = Image.open(io.BytesIO(image_data)).convert("RGB")
    transform = build_transform(input_size=input_size)
    pixel_values = transform(image).unsqueeze(0).to(torch.bfloat16).cuda()
    return pixel_values

# API nh·∫≠n ·∫£nh v√† th·ª±c hi·ªán OCR
@app.post("/ocr")
async def ocr(
    file: UploadFile = File(...),
    question: str = Form("<image>\nCh·ªâ ghi l·∫°i n·ªôi dung trong ·∫£nh d∆∞·ªõi d·∫°ng markdown")
):
    image_data = await file.read()
    pixel_values = process_image(image_data)

    # C·∫•u h√¨nh cho m√¥ h√¨nh
    generation_config = dict(max_new_tokens=512, do_sample=False, num_beams=3, repetition_penalty=3.5)
    
    # S·ª≠ d·ª•ng c√¢u h·ªèi t·ª´ client ho·∫∑c c√¢u h·ªèi m·∫∑c ƒë·ªãnh
    if not question.strip():
        question = "<image>\nCh·ªâ ghi l·∫°i n·ªôi dung trong ·∫£nh d∆∞·ªõi d·∫°ng markdown"
    
    # ƒê·∫£m b·∫£o c√¢u h·ªèi c√≥ ti·ªÅn t·ªë <image>
    if not question.startswith("<image>"):
        question = "<image>\n" + question
    
    # Ch·∫°y m√¥ h√¨nh ƒë·ªÉ nh·∫≠n di·ªán v√† tr·∫£ v·ªÅ k·∫øt qu·∫£
    response = model.chat(tokenizer, pixel_values, question, generation_config)

    return {"text": response}

# API ki·ªÉm tra tr·∫°ng th√°i server
@app.get("/health")
def health_check():
    return {"status": "online"}

# Ch·∫°y server
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
